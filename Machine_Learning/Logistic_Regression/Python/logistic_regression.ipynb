{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple logistic regression\n",
    "# 2017-03-11 jkang\n",
    "# Python3.5\n",
    "# Tensorflow1.0.1\n",
    "# ref:\n",
    "# - http://web.stanford.edu/class/cs20si/\n",
    "# - iris dataset from Matlab Neural Network example\n",
    "#\n",
    "# Input: iris data (4 features)\n",
    "# Output: iris label (3 categories)\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_Rate = 0.01\n",
    "batch_size = 10\n",
    "max_epochs = 30\n",
    "\n",
    "irisInputs_tmp = sio.loadmat('irisInputs.mat')\n",
    "irisInputs = irisInputs_tmp['irisInputs'].T\n",
    "irisTargets_tmp = sio.loadmat('irisTargets')\n",
    "irisTargets = irisTargets_tmp['irisTargets'].T\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, 4], name='irisInputs')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, 3], name='irisTargets')\n",
    "\n",
    "w = tf.Variable(np.zeros((4, 3)), name='weight', dtype=np.float32)\n",
    "b = tf.Variable(np.zeros((1, 3)), name='bias', dtype=np.float32)\n",
    "\n",
    "logits = tf.matmul(X, w) + b\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_Rate).minimize(loss)\n",
    "\n",
    "def softmax(x):\n",
    "    ex_val = np.exp(x - np.max(x))\n",
    "    return ex_val / ex_val.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 0: 1.0566088040669759\n",
      "Average loss at epoch 1: 0.9699530641237895\n",
      "Average loss at epoch 2: 0.9008939743041993\n",
      "Average loss at epoch 3: 0.844332234064738\n",
      "Average loss at epoch 4: 0.7976635773976644\n",
      "Average loss at epoch 5: 0.7587910453478496\n",
      "Average loss at epoch 6: 0.726058288415273\n",
      "Average loss at epoch 7: 0.6981823921203614\n",
      "Average loss at epoch 8: 0.6741775631904602\n",
      "Average loss at epoch 9: 0.6532862265904744\n",
      "Average loss at epoch 10: 0.6349237163861593\n",
      "Average loss at epoch 11: 0.6186354239781697\n",
      "Average loss at epoch 12: 0.6040651202201843\n",
      "Average loss at epoch 13: 0.5909309069315593\n",
      "Average loss at epoch 14: 0.5790078043937683\n",
      "Average loss at epoch 15: 0.568114572763443\n",
      "Average loss at epoch 16: 0.5581039170424144\n",
      "Average loss at epoch 17: 0.5488551616668701\n",
      "Average loss at epoch 18: 0.5402686436971028\n",
      "Average loss at epoch 19: 0.5322613716125488\n",
      "Average loss at epoch 20: 0.5247637848059337\n",
      "Average loss at epoch 21: 0.5177172323067983\n",
      "Average loss at epoch 22: 0.5110718568166097\n",
      "Average loss at epoch 23: 0.5047851463158926\n",
      "Average loss at epoch 24: 0.498820432027181\n",
      "Average loss at epoch 25: 0.4931462287902832\n",
      "Average loss at epoch 26: 0.4877350707848867\n",
      "Average loss at epoch 27: 0.4825630704561869\n",
      "Average loss at epoch 28: 0.477609250942866\n",
      "Average loss at epoch 29: 0.4728552341461182\n",
      "Optimization finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # training\n",
    "    writer = tf.summary.FileWriter('./graph', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(irisTargets.shape[0] / batch_size)\n",
    "    for i in range(max_epochs):\n",
    "        total_loss = 0\n",
    "        for ibatch in range(n_batches):\n",
    "            x_batch = irisInputs[batch_size *\n",
    "                                 ibatch: batch_size * ibatch + batch_size]\n",
    "            y_batch = irisTargets[batch_size *\n",
    "                                  ibatch: batch_size * ibatch + batch_size]\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={\n",
    "                                     X: x_batch, Y: y_batch})\n",
    "            total_loss += loss_batch\n",
    "        print('Average loss at epoch {0}: {1}'.format(\n",
    "            i, total_loss / n_batches))\n",
    "    print('Optimization finished!')\n",
    "    weights, bias = sess.run([w, b])\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: [0 0 1]\n",
      "pred: 3 th element\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "rand_idx = np.random.permutation(irisInputs.shape[0])[0]\n",
    "x_data = irisInputs[rand_idx]\n",
    "y_data = irisTargets[rand_idx]\n",
    "pred = softmax(np.dot(x_data, weights) + bias)\n",
    "print('Y:', y_data)\n",
    "print('pred:', np.argmax(pred) + 1, 'th element')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
